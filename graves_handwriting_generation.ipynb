{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handwriting Generaton with Recurrent Neural Networks and Mixture of Gaussians\n",
    "\n",
    "*Thomas Viehmann* <tv@learnapparat.de>\n",
    "\n",
    "This is a PyTorch implementation of the handwriting generation in Alex Graves' classic paper [Generating Sequences with Recurrent Neural Networks](https://arxiv.org/abs/1308.0850).\n",
    "In addition to replicating the model, I wanted to explore recreating the visualisations that Graves uses.\n",
    "\n",
    "I also studied [Alexandre de Brébisson's Theano implementation](https://github.com/adbrebs/handwriting), but all errors are my own.\n",
    "\n",
    "I can highly recommend the original paper, I enjoyed reading it a lot.\n",
    "\n",
    "**Note:** This notebook is written using PyTorch 0.4 (master at the time of writing).\n",
    "\n",
    "At popular request, I have you can get [pretrained model weights](https://github.com/t-vi/pytorch-tvmisc/releases/download/2018-03-13/graves_handwriting_generation_2018-03-13-02-45epoch_49.hd5). Use them with the load_from_hdf5 code below. They are not particularly tweaked but just the ones that I got when I ran the notebook for the outputs you see below.\n",
    "\n",
    "## Overview\n",
    "Besically we have the following architecture (shown in the diagram):\n",
    "- The triplets of relative movements in $x$ and $y$ direction and $pen$ (note this is different to Graves' notation, who uses $x$ for the triple) and a (attention-) mixture $w$ of one-hot encoded characters are fed into an **LSTM**, producing a hidden state $h$.\n",
    "- The **Attention** takes the sequence of one-hot encoded characters ($c$ in Graves) and the hidden state $h$ to weight $c$ and give a new mixture $w$ of $c$ items. The attention component remembers the location of the attention modes.\n",
    "- A **Mixture Density Network** (see [a short notebook here](https://github.com/t-vi/pytorch-tvmisc/blob/master/misc/Mixture_Density_Network_Gaussian_1d.ipynb)) takes the LSTM output $h$ and the attention-modulated character information $w$ to compute a Gaussian density mixture for the coordinates and a Bernoulli parameter for pen up/pen down. In training the negative log likelihood of the actual movement and pen is used, and for prediction, movement and pen are sampled.\n",
    "- A module wraps the three components and steps through the sequence.\n",
    "\n",
    "(I honestly don't know how to make those esges between timesteps closer...)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "310E031C764B4EC1B2A85C6D4173F490"
   },
   "outputs": [],
   "source": [
    "import graphviz\n",
    "g = graphviz.Digraph(graph_attr=dict(size=\"12,12\"))\n",
    "with g.subgraph() as dot:\n",
    "    g.node(\"pts(t-1)\",label=\"(X,Y,Pen)(t-1)\", shape=\"ellipse\", style=\"filled\")\n",
    "    g.node(\"txt\",label=\"Text\", style=\"filled\")\n",
    "    g.node(\"w(t-1)\", style=\"filled\")\n",
    "    g.edge(\"pts(t-1)\",\"txt\", style=\"invis\")\n",
    "    g.edge(\"txt\",\"w(t-1)\", style=\"invis\")\n",
    "for i,timestep in enumerate([\"t\",\"t+1\", \"t+2\"]):\n",
    "    with g.subgraph(name=\"cluster_{}\".format(timestep)) as dot:\n",
    "        dot.attr(label='Step {}'.format(timestep))\n",
    "        dot.attr(sortv=str(i+1))\n",
    "        dot.node(\"LSTM{}\".format(timestep),label=\"LSTM\", shape=\"box\", style=\"rounded\")\n",
    "        dot.node(\"GMM{}\".format(timestep),label=\"Mixture Density\", shape=\"box\", style=\"rounded\")\n",
    "        dot.node(\"ATT{}\".format(timestep),label=\"Attention\", shape=\"box\", style=\"rounded\")\n",
    "        dot.node(\"pts({})\".format(timestep),label=\"(X,Y,Pen)({})\".format(timestep), shape=\"ellipse\", style=\"filled\")\n",
    "        dot.node(\"h({})\".format(timestep), shape=\"ellipse\", style=\"filled\")\n",
    "        dot.node(\"w({})\".format(timestep), shape=\"ellipse\", style=\"filled\")\n",
    "        dot.edge(\"h({})\".format(timestep), \"ATT{}\".format(timestep))\n",
    "        dot.edge(\"LSTM{}\".format(timestep),\"h({})\".format(timestep))\n",
    "        dot.edge(\"h({})\".format(timestep), \"GMM{}\".format(timestep))\n",
    "        dot.edge(\"ATT{}\".format(timestep), \"w({})\".format(timestep))\n",
    "        dot.edge(\"w({})\".format(timestep), \"GMM{}\".format(timestep))\n",
    "        dot.edge(\"GMM{}\".format(timestep), \"pts({})\".format(timestep), style=\"dashed\", label=\"predict\")\n",
    "\n",
    "\n",
    "g.edge(\"pts(t-1)\", \"LSTMt\", constraint=\"false\")\n",
    "g.edge(\"w(t-1)\", \"LSTMt\", constraint=\"false\")\n",
    "g.edge(\"txt\", \"ATTt\", constraint=\"false\")\n",
    "g.edge(\"txt\", \"ATTt+1\", constraint=\"false\")\n",
    "g.edge(\"txt\", \"ATTt+2\", constraint=\"false\")\n",
    "g.edge(\"w(t)\",\"LSTMt+1\",constraint=\"false\")\n",
    "g.edge(\"w(t+1)\",\"LSTMt+2\",constraint=\"false\")\n",
    "g.edge(\"pts(t)\",\"LSTMt+1\",constraint=\"false\")\n",
    "g.edge(\"pts(t+1)\",\"LSTMt+2\",constraint=\"false\")\n",
    "g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "310E031C764B4EC1B2A85C6D4173F490"
   },
   "source": [
    "First let us import something."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": "310E031C764B4EC1B2A85C6D4173F490"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f2cdcc1a610>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import time\n",
    "import collections\n",
    "import numpy\n",
    "import IPython\n",
    "import cairocffi as cairo\n",
    "from matplotlib import pyplot\n",
    "import matplotlib\n",
    "import torchtext\n",
    "import tqdm\n",
    "import glob\n",
    "import lxml.etree\n",
    "%matplotlib inline\n",
    "import torch\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The dataset\n",
    "\n",
    "The [IAM Online Handwriting Database](http://www.fki.inf.unibe.ch/databases/iam-online-document-database/iam-online-document-database) is provided by [E. Indermühle, M. Liwicki, and H. Bunke: IAMonDo-database: an Online Handwritten Document Database with Non-uniform Contents. Proc 9th Int. Workshop on Document Analysis Systems, 2010.](http://www.fki.inf.unibe.ch/databases/iam-online-document-database/das10db.pdf).\n",
    "\n",
    "The set is split into a training and three test sets, the latter being labeled *v*, *f*, and *t*. Following Graves, Section 4, we use the *v* set as validation and combine the other three for training.\n",
    "\n",
    "I used to have a separate preprocessing notebook, but preprocessing takes less than 30 seconds for me, so I just moved it here..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "iam_dir = \"data/iam/\"\n",
    "orig_trainset = [l.strip() for l in open(os.path.join(iam_dir, \"trainset.txt\"))]\n",
    "orig_testset_v = [l.strip() for l in open(os.path.join(iam_dir, \"testset_v.txt\"))] # smallest\n",
    "orig_testset_f = [l.strip() for l in open(os.path.join(iam_dir, \"testset_f.txt\"))]\n",
    "orig_testset_t = [l.strip() for l in open(os.path.join(iam_dir, \"testset_t.txt\"))]\n",
    "\n",
    "trainset = orig_trainset + orig_testset_f + orig_testset_t\n",
    "validset = orig_testset_v\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains ascii files with the text and xml-based representations of the strokes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "blacklist = {\"a08-551z-08\",\"a08-551z-09\"} # these seem broken\n",
    "\n",
    "def process_set(theset):\n",
    "    txts = {}\n",
    "    for i,n in enumerate(theset):\n",
    "        txtfn = \"data/iam/ascii/{}/{}/{}.txt\".format(n[:3], n[:7], n)\n",
    "        for j,t in enumerate(open(txtfn).read().split(\"CSR:\")[1].strip().split(\"\\n\")):\n",
    "            txts['{}-{:02d}'.format(n,j+1)] = t\n",
    "    samples = {}\n",
    "    for i,n in tqdm.tqdm(enumerate(theset),total=len(theset)):\n",
    "        globmask = \"data/iam/lineStrokes/{}/{}/{}-*.xml\".format(n[:3], n[:7], n)\n",
    "        for fn in glob.glob(globmask):\n",
    "            key = (os.path.splitext(os.path.basename(fn))[0])\n",
    "            if key not in blacklist:\n",
    "                root = lxml.etree.parse(fn).getroot()\n",
    "                strokes_list = []\n",
    "                for s in root.find(\"StrokeSet\").findall(\"Stroke\"):\n",
    "                    pts = torch.FloatTensor([(float(p.attrib['x']), float(p.attrib['y']),0.0) for p in s.findall(\"Point\")])\n",
    "                    pts[-1,-1] = 1\n",
    "                    strokes_list.append(pts)\n",
    "                strokes = torch.cat(strokes_list, dim=0)\n",
    "                (min_x,min_y),_ = torch.min(strokes[:,:2],dim=0)\n",
    "                (max_x,max_y),_ = torch.max(strokes[:,:2],dim=0)\n",
    "                rel_strokes = torch.cat([torch.zeros(1,3),\n",
    "                                         torch.cat([strokes[1:,:2]-strokes[:-1,:2],strokes[1:,2:]],dim=1)], dim=0)\n",
    "                if rel_strokes.abs().max()<1000: # we assume that such large moves are broken\n",
    "                    samples[key] = {\"strokes\":strokes_list, \"minmax\":(min_x,min_y,max_x,max_y), \"rel_strokes\":rel_strokes,\n",
    "                                    \"txt\": txts[key]}\n",
    "    return samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1535/1535 [00:48<00:00, 31.60it/s]\n",
      "100%|██████████| 192/192 [00:06<00:00, 29.22it/s]\n"
     ]
    }
   ],
   "source": [
    "training_samples = process_set(trainset)\n",
    "#torch.save(training_samples, \"preprocessed-training.pt\")\n",
    "val_samples = process_set(validset)\n",
    "#torch.save(val_samples, \"preprocessed-validation.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean tensor([8.1842, 0.1145]) std tensor([40.3660, 37.0441])\n"
     ]
    }
   ],
   "source": [
    "x = torch.cat([d[\"rel_strokes\"] for d in training_samples.values()], dim=0)\n",
    "mean,std = x[:,:2].mean(0),x[:,:2].std(0)\n",
    "print (\"mean\", mean, \"std\", std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a torchtext dataset to use our preprocessed IAM online handwriting data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cell_id": "BB01C85EE70F4A9686266712878C69A9"
   },
   "outputs": [],
   "source": [
    "char_dict = {k:v for v,k in enumerate(' !\"#%&\\'()+,-./0123456789:;?ABCDEFGHIJKLMNOPQRSTUVWXYZ[]abcdefghijklmnopqrstuvwxyz')}\n",
    "inv_char_dict = {v:k for k,v in char_dict.items()}\n",
    "n_chars = len(char_dict)\n",
    "\n",
    "class DS(torchtext.data.Dataset):\n",
    "    def __init__(self, samples, mean, std):\n",
    "        self.myfields = [('txt',torchtext.data.Field(use_vocab=True,tokenize=list, eos_token='<eos>')), \n",
    "                         ('txtn',torchtext.data.Field(use_vocab=False,pad_token=0)), \n",
    "                         ('txtlen',torchtext.data.Field(use_vocab=False)),\n",
    "                         ('txtmask',torchtext.data.Field(use_vocab=False,pad_token=0, dtype=torch.float)),\n",
    "                         ('xs',torchtext.data.Field(use_vocab=False, pad_token=-1, dtype=torch.float)),\n",
    "                         ('ys',torchtext.data.Field(use_vocab=False, pad_token=-1, dtype=torch.float)),\n",
    "                         ('pen',torchtext.data.Field(use_vocab=False,pad_token=-1)),\n",
    "                         ('ptslen',torchtext.data.Field(use_vocab=False))\n",
    "                        ]\n",
    "        self.coord_mean = mean\n",
    "        self.coord_std  = std\n",
    "        examples = []\n",
    "        for s in samples.values():\n",
    "            txt = [c for c in s[\"txt\"] if c in char_dict]\n",
    "            txtn = torch.LongTensor([char_dict[i] for i in txt])\n",
    "            txtlen = torch.LongTensor([len(txt)])\n",
    "            txtmask = torch.ones(len(txt))\n",
    "            stroke = s['rel_strokes']\n",
    "            xs = stroke[:,0]\n",
    "            ys = stroke[:,1]\n",
    "            pen = stroke[:,2]\n",
    "            ptslen = torch.LongTensor([len(pen)])\n",
    "            if xs.abs().max()<1000 and ys.abs().max()<1000 and len(txt)>=20:\n",
    "                xs = (xs-self.coord_mean[0])/self.coord_std[0]\n",
    "                ys = (ys-self.coord_mean[1])/self.coord_std[1]\n",
    "                examples.append(torchtext.data.Example.fromlist([txt, txtn, txtlen, txtmask,\n",
    "                                                            xs, ys, pen, ptslen\n",
    "                                                            ], self.myfields))        \n",
    "        super(DS, self).__init__(examples, self.myfields)\n",
    "        self.myfields[0][1].build_vocab(self)\n",
    "    def sort_key(self, ex):\n",
    "        return len(ex.txt)\n",
    "    def tensor_to_str(self,t):\n",
    "        return ''.join([self.fields['txt'].vocab.itos[c] for c in t if c >= 3])\n",
    "    def tensor_to_str2(self,t):\n",
    "        return ''.join([inv_char_dict[c] for c in t])\n",
    "\n",
    "train_ds = DS(training_samples, mean, std)\n",
    "val_ds   = DS(val_samples, mean, std)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is both a matplotlib-based and a cairo-based function to display a stroke.\n",
    "The cairo-based function is a lot faster and optionally add random shear and rotation, the matplotlib-based one offers color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cell_id": "9C2DFE5CE8B645A28C47AAA32ED8CE32"
   },
   "outputs": [],
   "source": [
    "def show_stroke(x, colors=None):   \n",
    "    x= x[:(torch.arange(0,x.size(0))[x[:,2]>-0.0001].size(0))] # only used bits\n",
    "    stroke = (x[:,:2]*train_ds.coord_std.unsqueeze(0)+train_ds.coord_mean.unsqueeze(0)).cumsum(0)\n",
    "    stroke[:,1] *= -1\n",
    "    pen = x[:,2]\n",
    "    xmin,ymin = stroke.min(0)[0]\n",
    "    xmax,ymax = stroke.max(0)[0]\n",
    "    \n",
    "    actions = [matplotlib.path.Path.MOVETO]\n",
    "    coords = []\n",
    "    for c,p in zip(stroke, pen):\n",
    "        if p >=-0.0001:\n",
    "          if p==1 or len(actions)==0:\n",
    "            actions.append(matplotlib.path.Path.MOVETO)\n",
    "          else:\n",
    "            actions.append(matplotlib.path.Path.LINETO)\n",
    "          coords.append((c[0],c[1]))\n",
    "    actions = actions[:-1]\n",
    "    ax = pyplot.gca()\n",
    "    ax.set_xlim(xmin, xmax)\n",
    "    ax.set_ylim(ymin, ymax)\n",
    "\n",
    "    if colors is None:\n",
    "        path = matplotlib.path.Path(coords, actions)\n",
    "        patch = matplotlib.patches.PathPatch(path, facecolor='none')\n",
    "        ax.add_patch(patch)\n",
    "    else:\n",
    "        pos = coords[0]\n",
    "        curpos = pos\n",
    "        for pos,a,col in zip(coords, actions, colors):\n",
    "            if a == matplotlib.path.Path.LINETO:\n",
    "                ax.add_line(matplotlib.lines.Line2D((curpos[0],pos[0]), (curpos[1],pos[1]), axes=ax, color=col))\n",
    "            curpos = pos\n",
    "\n",
    "\n",
    "def stroke_to_image(x, target_size = (1280,64), randomize=False):\n",
    "    stroke = (x[:,:2]*train_ds.coord_std.unsqueeze(0)+train_ds.coord_mean.unsqueeze(0)).cumsum(0)\n",
    "    pen = x[:,2]\n",
    "    if randomize:\n",
    "        shear_prob = 0.5\n",
    "        shear_prec = 4.0\n",
    "        if torch.rand(1)[0] > shear_prob:\n",
    "            shear_sigma = 1/shear_prec**0.5\n",
    "            shear_theta = 0.5*torch.randn(1)    \n",
    "        else:\n",
    "            shear_theta = torch.zeros(1)\n",
    "        rot_prob = 0.5\n",
    "        rot_prec = 4.0\n",
    "        if torch.rand(1)[0] > rot_prob:\n",
    "            rot_sigma = 1/rot_prec**0.5\n",
    "            rot_theta = 0.5*torch.randn(1)    \n",
    "        else:\n",
    "            rot_theta = torch.zeros(1)\n",
    "\n",
    "        (min_x,min_y),_ = torch.min(stroke[:,:2],dim=0)\n",
    "        (max_x,max_y),_ = torch.max(stroke[:,:2],dim=0)\n",
    "        stroke[:,0] -= min_x\n",
    "        stroke[:,1] -= min_y  \n",
    "        min_x, min_y = 0.0,0.0\n",
    "        max_x, max_y = max_x-min_x, max_y-min_y\n",
    "\n",
    "        stroke[:,0] += stroke[:,1]*torch.sin(shear_theta)\n",
    "\n",
    "        stroke[:,0] = stroke[:,0]*torch.cos(rot_theta)+stroke[:,1]*torch.sin(rot_theta)\n",
    "        stroke[:,1] = stroke[:,1]*torch.cos(rot_theta)-stroke[:,0]*torch.sin(rot_theta)\n",
    "\n",
    "    (min_x,min_y),_ = torch.min(stroke[:,:2],dim=0)\n",
    "    (max_x,max_y),_ = torch.max(stroke[:,:2],dim=0)\n",
    "    stroke[:,0] -= min_x\n",
    "    stroke[:,1] -= min_y  \n",
    "    min_x, min_y = 0.0,0.0\n",
    "    max_x, max_y = max_x-min_x, max_y-min_y\n",
    "\n",
    "    factor = min(target_size[0]/max(max_x-min_x,0.001),target_size[1]/max(max_y-min_y,0.001),1)\n",
    "    xmin,ymin = stroke.min(0)[0]\n",
    "    xmax,ymax = stroke.max(0)[0]\n",
    "\n",
    "    imwidth, imheight = int(xmax*factor)+2, int(ymax*factor)+2\n",
    "    surface = cairo.ImageSurface (cairo.FORMAT_A8, imwidth, imheight)\n",
    "    ctx = cairo.Context(surface)\n",
    "\n",
    "    ctx.scale (factor, factor) # Normalizing the canvas\n",
    "    ctx.rectangle (0, 0, xmax+5/factor, ymax+5/factor) # Rectangle(x0, y0, x1, y1)\n",
    "    ctx.set_source_rgba (0.0, 0.0, 0.0, 0.0) # Solid color\n",
    "    ctx.fill ()\n",
    "    next_action = 1\n",
    "    coords = []\n",
    "    for c,p in zip(stroke, pen):\n",
    "        if p >=-0.0001:\n",
    "          if next_action:\n",
    "            ctx.move_to(c[0]+1,c[1]+1)\n",
    "          else:\n",
    "            ctx.line_to(c[0]+1,c[1]+1)\n",
    "          next_action = p>0.5\n",
    "    ctx.set_source_rgba(1.0, 1.0, 1.0, 1.0) # Solid color\n",
    "\n",
    "    \n",
    "    if randomize:\n",
    "        linewidth = (1+torch.rand(1)[0])/factor\n",
    "    else:\n",
    "        linewidth = 2/factor\n",
    "    ctx.set_line_width (linewidth)\n",
    "    ctx.stroke ()\n",
    "\n",
    "    buf = surface.get_data()\n",
    "    data = numpy.ndarray(shape=(imheight, (imwidth+3)//4*4),#(WIDTH+7)//8),\n",
    "                         dtype=numpy.uint8,\n",
    "                         buffer=buf)[:,:imwidth]\n",
    "    data = 1-(data>0)\n",
    "    data = torch.FloatTensor(data)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "7FAF0988C7FF480982084244884101F3"
   },
   "source": [
    "Let us see an example of our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cell_id": "449FD1CD6C2D440795EA35A83BF5A100"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'at Lancaster House despite the crisis which'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "b = train_ds[0]\n",
    "pts = torch.stack([b.xs,b.ys,b.pen.float()],dim=-1)\n",
    "pyplot.figure(figsize=(10,5))\n",
    "pyplot.imshow(stroke_to_image(pts[:b.ptslen[0]].cpu()), cmap=pyplot.cm.gray)\n",
    "''.join(b.txt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The network\n",
    "\n",
    "### Mixture Density Network\n",
    "\n",
    "The mixture density network, described in Graves Section 4.1, consists of a linear layer and parameter transforms in `compute_params`.\n",
    "The parameters are\n",
    "- a vector $\\pi$ with the weights of the mixture components, \n",
    "- vectors (one element per mixture component)`mean_x, mean_y` ($\\mu$ in Graves), `std_x, std_y` ($\\sigma$), and $\\rho$,\n",
    "- a probaility `bernoulli` ($e$ in Graves) of the pen being up (i.e. $1$ means no pen).\n",
    "\n",
    "Then for training (in `forward`), the negative log likelihood is computer. For prediction (`predict`), movement and pen indicator are sampled.\n",
    "In the prediction, we allow for bias ($b$) as in Graves Section 5.4.\n",
    "\n",
    "We found that the training sometimes runs into `NaN` unless we use some regularisation, we do so via a parameter `eps`.\n",
    "This may be due to us using single precision floating point numbers rather than double precision or a too aggressive learning rate.\n",
    "We also see below that we do not seem to achieve the deterministic outputs when the bias is high.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MixtureGaussians2DandPen(torch.nn.Module):\n",
    "    \"\"\"Gaussian mixture module as in Graves Section 4.1\"\"\"\n",
    "    def __init__(self, n_inputs, n_mixture_components, eps=1e-6):\n",
    "        # n_inputs = dimension N of h^n_t in Graves eq. (17)\n",
    "        # n_mixture_components = number M of mixture components in Graves eq. (16)\n",
    "        super().__init__()\n",
    "        self.n_mixture_components = n_mixture_components\n",
    "        self.eps = eps\n",
    "        # linear layer as in Graves eq. (17)\n",
    "        # ((proportions, m_x, m_y, s_x, s_y, rho)*n_mixture_components, pen)\n",
    "        self.linear = torch.nn.Linear(n_inputs, n_mixture_components *6 + 1) \n",
    "\n",
    "    def compute_parameters(self, h, bias):\n",
    "        # h: batch x n_inputs\n",
    "        # The output of the input layer is batch x ...\n",
    "        y_hat = self.linear(h)\n",
    "        if y_hat.requires_grad:\n",
    "            y_hat.register_hook(lambda x: x.clamp(min=-100, max=100))\n",
    "        \n",
    "        M = self.n_mixture_components\n",
    "        # note that our ordering within y_hat is different to Graves eq (17)\n",
    "        # we also incorporate the bias b given in Graves eq (61) and (62)\n",
    "        # we have a regularisation self.eps that Graves does not have in the paper\n",
    "        pi = torch.nn.functional.softmax(y_hat[:, :M]*(1 + bias),1) # Graves eq (19)\n",
    "        mean_x = y_hat[:, M:M*2]                                      # Graves eq (20)\n",
    "        mean_y = y_hat[:, M*2:M*3]\n",
    "        std_x = torch.exp(y_hat[:, M*3:M*4] - bias) + self.eps        # Graves eq (21)\n",
    "        std_y = torch.exp(y_hat[:, M*4:M*5] - bias) + self.eps\n",
    "        rho = torch.tanh(y_hat[:, M*5:M*6])                           # Graves eq (22)\n",
    "        rho = rho/(1+self.eps)\n",
    "        bernoulli = torch.sigmoid(y_hat[:, -1])                       # Graves eq (18)\n",
    "        bernoulli = (bernoulli + self.eps) / (1 + 2*self.eps)\n",
    "        #bernoulli = 1/(1+torch.exp(-(1+bias)*((torch.log(bernoulli)-torch.log(1-bernoulli))+3*(1-torch.exp(-bias))))) # this is NOT covered by Graves: Bias in the Bernoulli\n",
    "        return pi, mean_x, mean_y, std_x, std_y, rho, bernoulli\n",
    "\n",
    "    def predict(self, h, bias=0.0):\n",
    "        pi, mean_x, mean_y, std_x, std_y, rho, bernoulli = self.compute_parameters(h, bias)\n",
    "\n",
    "        mode = torch.multinomial(pi.data,1) # choose one mixture component\n",
    "\n",
    "        m_x = mean_x.gather(1, mode).squeeze(1) # data for the chosen mixture component\n",
    "        m_y = mean_y.gather(1, mode).squeeze(1)\n",
    "        s_x = std_x.gather(1, mode).squeeze(1)\n",
    "        s_y = std_y.gather(1, mode).squeeze(1)\n",
    "        r   = rho.gather(1, mode).squeeze(1)\n",
    "\n",
    "        normal = rho.new().resize_((h.size(0), 2)).normal_()\n",
    "        x = normal[:, 0]\n",
    "        y = normal[:, 1]\n",
    "\n",
    "        x_n = (m_x + s_x * x).unsqueeze(-1)\n",
    "        y_n = (m_y + s_y * (x * r + y * (1.-r**2)**0.5)).unsqueeze(-1)\n",
    "\n",
    "        uniform = bernoulli.data.new(h.size(0)).uniform_()\n",
    "        pen = torch.autograd.Variable((bernoulli.data > uniform).float().unsqueeze(-1))\n",
    "\n",
    "        return torch.cat([x_n, y_n, pen], dim=1)\n",
    "\n",
    "    def forward(self, h_seq, mask_seq, tg_seq, hidden_dict=None):\n",
    "        # h_seq: (seq, batch, features),  mask_seq: (seq, batch), tg_seq: (seq, batch, features=3)\n",
    "        batch_size = h_seq.size(1)\n",
    "        h_seq = h_seq.view(-1, h_seq.size(-1))\n",
    "        tg_seq = tg_seq.view(-1, tg_seq.size(-1))\n",
    "        mask_seq = mask_seq.view(-1,)\n",
    "\n",
    "        atensor = next(self.parameters())\n",
    "        bias = torch.zeros((),device=atensor.get_device(), dtype=atensor.dtype)\n",
    "        pi, mean_x, mean_y, std_x, std_y, rho, bernoulli = self.compute_parameters(h_seq, bias)\n",
    "\n",
    "        if hidden_dict is not None:\n",
    "            hidden_dict[\"pi\"].append(pi.data.cpu())\n",
    "            hidden_dict[\"mean_x\"].append(mean_x.data.cpu())\n",
    "            hidden_dict[\"mean_y\"].append(mean_y.data.cpu())\n",
    "            hidden_dict[\"std_x\"].append(std_x.data.cpu())\n",
    "            hidden_dict[\"std_y\"].append(std_y.data.cpu())\n",
    "            hidden_dict[\"rho\"].append(rho.data.cpu())\n",
    "            hidden_dict[\"bernoulli\"].append(bernoulli.data.cpu())\n",
    "\n",
    "        tg_x = tg_seq[:, 0:1]\n",
    "        tg_y = tg_seq[:, 1:2]\n",
    "        tg_pen = tg_seq[:, 2]\n",
    "\n",
    "        tg_x_s = (tg_x - mean_x) / std_x \n",
    "        tg_y_s = (tg_y - mean_y) / std_y\n",
    "\n",
    "        z = tg_x_s**2 + tg_y_s**2 - 2*rho*tg_x_s*tg_y_s # Graves eq (25)\n",
    "        \n",
    "        if hidden_dict is not None:\n",
    "            hidden_dict[\"z\"].append(z.data.cpu())            \n",
    "\n",
    "        tmp = 1-rho**2\n",
    "        # tmp is ln (pi N(x, mu, sigma, rho)) with N as in Graves eq (24) (this is later used for eq (26))\n",
    "        mixture_part_loglikelihood = (-z / (2 * tmp) \n",
    "                              -numpy.log(2*numpy.pi) - torch.log(std_x) - torch.log(std_y) - 0.5*torch.log(tmp)\n",
    "                              +torch.log(pi))\n",
    "\n",
    "        # logsumexp over the mixture components\n",
    "        # mixture_log_likelihood the log in the first part of Graves eq (26)\n",
    "        mpl_max,_ = mixture_part_loglikelihood.max(1, keepdim=True)                                 \n",
    "        mixture_log_likelihood = (mixture_part_loglikelihood-mpl_max).exp().sum(1).log()+mpl_max.squeeze(1)\n",
    "\n",
    "        # these are the summands in Graves eq (26)\n",
    "        loss_per_timestep = (-mixture_log_likelihood - tg_pen * torch.log(bernoulli) - (1-tg_pen) * torch.log(1 - bernoulli))\n",
    "\n",
    "        if hidden_dict is not None:\n",
    "            hidden_dict[\"loss_per_timestep\"].append(loss_per_timestep.data.cpu())\n",
    "        # loss as in Graves eq (26)\n",
    "        loss = torch.sum(loss_per_timestep * mask_seq)/batch_size\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention Mechanism\n",
    "\n",
    "Graves Section 5.1 describes a straightforward attention mechanism using a mixture-type weighting scheme and with moving modes.\n",
    "In addition to the one-hot encoded character sequence, the input for the attention mechanism is the LSTM-output $h$ and the previous time-steps mode locations $\\kappa_{t-1}^k$.\n",
    "More precisely, weights $\\phi$ are computed as\n",
    "$$\n",
    "\\phi(t, u) = \\sum_k \\alpha_t^k \\exp(-\\beta_t^k (\\kappa_t^k-u)^2)\n",
    "$$\n",
    "with $t$ being the recurrence time step, $u$ the character location and $k$ is used to sum over the components.\n",
    "Here, $\\alpha_t^k, \\beta_t^k$ and $\\kappa_t^k-\\kappa_{t-1}^k$ are positive - mapped by $\\exp$ from the output of a linear layer. For the $\\kappa_t^k$, the difference is modelled to achieve better stationarity.\n",
    "The module returns the weight vector $\\phi$ and the mode location vector $\\kappa$.\n",
    "\n",
    "Graves notes he does not normalize the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(torch.nn.Module):\n",
    "    def __init__(self, n_inputs, n_mixture_components):\n",
    "        super().__init__()\n",
    "        self.n_mixture_components = n_mixture_components\n",
    "        # linear layer from Graves eq (28)\n",
    "        self.linear = torch.nn.Linear(n_inputs, n_mixture_components*3)\n",
    "    def forward(self, h_1, kappa_prev, c_seq_len):\n",
    "        # h_1: batch x n_inputs, kappa_prev batch x n_mixture_components\n",
    "        K = self.n_mixture_components\n",
    "        params = torch.exp(self.linear(h_1)) # exp of Graves eq (48)\n",
    "        alpha = params[:,:K]                 # Graves eq (49)\n",
    "        beta  = params[:,K:2*K]              # Graves eq (50)\n",
    "        kappa = kappa_prev + 0.1*params[:,2*K:]  # Graves eq (51)\n",
    "        u = torch.arange(0,c_seq_len, out=kappa.new()).view(-1,1,1)\n",
    "        phi = torch.sum(alpha * torch.exp(-beta*(kappa-u)**2), dim=-1)\n",
    "        return phi, kappa\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM\n",
    "\n",
    "In order to be able to trade the LSTM cell for a GRU, I have a thin wraper around the LSTMCell module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNCell(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, bias=True):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.cell = torch.nn.LSTMCell(input_size, hidden_size, bias)\n",
    "    def forward(self, inp, hidden = None):\n",
    "        if hidden is None:\n",
    "            batch_size = inp.size(0)\n",
    "            hx = inp.new(batch_size, self.hidden_size).zero_()\n",
    "            cx = inp.new(batch_size, self.hidden_size).zero_()\n",
    "            hidden = (hx, cx)\n",
    "        return self.cell(inp, hidden)\n",
    "    def get_hidden(self, hidden):\n",
    "        return hidden[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Module\n",
    "\n",
    "Tying things together is the main module. It is disappointingly heavyweight given that it mostly does administraton.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "cell_id": "4AFBD0DFCE2147588AB92E4813E9041F"
   },
   "outputs": [],
   "source": [
    "class HandwritingModel(torch.nn.Module):\n",
    "    def __init__(self, n_hidden, n_chars, n_attention_components, n_gaussians, grad_clipping=10):\n",
    "        super(HandwritingModel, self).__init__()\n",
    "        self.n_hidden = n_hidden\n",
    "        self.n_chars = n_chars\n",
    "        self.n_attention_components = n_attention_components\n",
    "        self.n_gaussians = n_gaussians\n",
    "\n",
    "        self.attention = Attention(n_hidden, n_attention_components)\n",
    "        self.rnn_cell = RNNCell(3+self.n_chars, n_hidden)\n",
    "        self.grad_clipping = grad_clipping\n",
    "        self.mixture = MixtureGaussians2DandPen(n_hidden+self.n_chars, n_gaussians)\n",
    "\n",
    "    def rnn_step(self, inputs, h_state_pre, k_pre, w_pre, c, c_mask, mask=None, hidden_dict=None):\n",
    "        # inputs: (batch_size, n_in + n_in_c)\n",
    "        inputs = torch.cat([inputs, w_pre], dim=1)\n",
    "\n",
    "        # h: (batch_size, n_hidden)\n",
    "        h_state = self.rnn_cell(inputs, h_state_pre)\n",
    "        h = self.rnn_cell.get_hidden(h_state)\n",
    "        if h.requires_grad:\n",
    "            h.register_hook(lambda x: x.clamp(min=-self.grad_clipping, max=self.grad_clipping))\n",
    "            \n",
    "        # update attention\n",
    "        phi, k =  self.attention(h, k_pre, c.size(0))\n",
    "        phi = phi * c_mask\n",
    "        # w: (batch_size, n_chars)\n",
    "        w = torch.sum(phi.unsqueeze(-1) * c, dim=0)\n",
    "        if mask is not None:\n",
    "            k = mask.unsqueeze(1)*k + (1-mask.unsqueeze(1))*k_pre\n",
    "            w = mask.unsqueeze(1)*w + (1-mask.unsqueeze(1))*w_pre\n",
    "        if w.requires_grad:\n",
    "            w.register_hook(lambda x: x.clamp(min=-100, max=100))\n",
    "        return h_state, k, phi, w\n",
    "    \n",
    "    def forward(self, seq_pt, seq_mask, seq_pt_target, c, c_mask,\n",
    "                h_ini=None, k_ini=None, w_ini=None, hidden_dict=None):       \n",
    "        batch_size = seq_pt.size(1)\n",
    "        atensor = next(m.parameters())\n",
    "        \n",
    "        #if h_ini is None:\n",
    "        #    h_ini = self.mixture.linear.weight.data.new(batch_size, self.n_hidden).zero_()\n",
    "        if k_ini is None:\n",
    "            k_ini = atensor.new(batch_size, self.n_attention_components).zero_()\n",
    "        if w_ini is None:\n",
    "            w_ini = atensor.new(batch_size, self.n_chars).zero_()\n",
    "\n",
    "        # Convert the integers representing chars into one-hot encodings\n",
    "        # seq_str will have shape (seq_length, batch_size, n_chars)\n",
    "        \n",
    "        c_idx = c\n",
    "        c = c.data.new(c.size(0), c.size(1), self.n_chars).float().zero_()\n",
    "        c.scatter_(2, c_idx.view(c.size(0), c.size(1), 1), 1)\n",
    "\n",
    "        seq_h = []\n",
    "        seq_k = []\n",
    "        seq_w = []\n",
    "        seq_phi = []\n",
    "        h_state, k, w = h_ini, k_ini, w_ini\n",
    "        for inputs, mask in zip(seq_pt, seq_mask):\n",
    "            h_state, k, phi, w = self.rnn_step(inputs, h_state, k, w, c, c_mask, mask=mask, hidden_dict=hidden_dict)\n",
    "            h = self.rnn_cell.get_hidden(h_state)\n",
    "            seq_h.append(h)\n",
    "            seq_k.append(k)\n",
    "            seq_w.append(w)\n",
    "            if hidden_dict is not None:\n",
    "                seq_phi.append(phi)\n",
    "        seq_h = torch.stack(seq_h,0)\n",
    "        seq_k = torch.stack(seq_k,0)\n",
    "        seq_w = torch.stack(seq_w,0)\n",
    "        if hidden_dict is not None:\n",
    "            hidden_dict['seq_h'].append(seq_h.data.cpu())\n",
    "            hidden_dict['seq_k'].append(seq_k.data.cpu())\n",
    "            hidden_dict['seq_w'].append(seq_w.data.cpu())\n",
    "            hidden_dict['seq_phi'].append(torch.stack(seq_phi,0).data.cpu())\n",
    "        seq_hw = torch.cat([seq_h, seq_w], dim=-1)\n",
    "\n",
    "        loss = self.mixture(seq_hw, seq_mask, seq_pt_target, hidden_dict=hidden_dict)\n",
    "        return loss\n",
    "\n",
    "    def predict(self, pt_ini, seq_str, seq_str_mask,\n",
    "                   h_ini=None, k_ini=None, w_ini=None, bias=.0, n_steps=10000, hidden_dict=None):\n",
    "        # pt_ini: (batch_size, 3), seq_str: (length_str_seq, batch_size), seq_str_mask: (length_str_seq, batch_size)\n",
    "        # h_ini: (batch_size, n_hidden), k_ini: (batch_size, n_mixture_attention), w_ini: (batch_size, n_chars)\n",
    "        # bias: float    The bias that controls the variance of the generation\n",
    "        # n_steps: int   The maximal number of generation steps.\n",
    "        atensor = next(m.parameters())\n",
    "        bias = bias*torch.ones((),device=atensor.get_device(), dtype=atensor.dtype)\n",
    "        batch_size = pt_ini.size(0)\n",
    "        if k_ini is None:\n",
    "            k_ini = atensor.new(batch_size, self.n_attention_components).zero_()\n",
    "        if w_ini is None:\n",
    "            w_ini = atensor.new(batch_size, self.n_chars).zero_()\n",
    "\n",
    "        # Convert the integers representing chars into one-hot encodings\n",
    "        # seq_str will have shape (seq_length, batch_size, n_chars)\n",
    "        \n",
    "        input_seq_str = seq_str\n",
    "        seq_str = pt_ini.data.new(input_seq_str.size(0), input_seq_str.size(1), self.n_chars).float().zero_()\n",
    "        seq_str.scatter_(2, input_seq_str.data.view(seq_str.size(0), seq_str.size(1) ,1), 1)\n",
    "        seq_str = torch.autograd.Variable(seq_str)        \n",
    "\n",
    "        mask = torch.autograd.Variable(self.mixture.linear.weight.data.new(batch_size).fill_(1))\n",
    "        seq_pt = [pt_ini]\n",
    "        seq_mask = [mask]\n",
    "\n",
    "        last_char = seq_str_mask.long().sum(0)-1\n",
    "\n",
    "        pt, h_state, k, w = pt_ini, h_ini, k_ini, w_ini\n",
    "        for i in range(n_steps):\n",
    "            h_state, k, phi, w = self.rnn_step(pt, h_state, k, w, seq_str, seq_str_mask, mask=mask, hidden_dict=hidden_dict)\n",
    "            h = self.rnn_cell.get_hidden(h_state)\n",
    "            hw = torch.cat([h, w], dim=-1)\n",
    "            pt = self.mixture.predict(hw, bias)\n",
    "            seq_pt.append(pt)\n",
    "            \n",
    "            last_phi = torch.gather(phi, 0, last_char.unsqueeze(0)).squeeze(0)\n",
    "            max_phi,_ = phi.max(0)\n",
    "            mask = mask * (1-(last_phi >= 0.95*max_phi).float())\n",
    "            seq_mask.append(mask)\n",
    "            if mask.data.sum()==0:\n",
    "                break\n",
    "        seq_pt   = torch.stack(seq_pt,0)\n",
    "        seq_mask = torch.stack(seq_mask,0)\n",
    "        return seq_pt, seq_mask        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "478F522049C049AA8B8F818CEB567B22"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "cell_id": "998AED33563E45F78A2CE8759B69A4BF"
   },
   "outputs": [],
   "source": [
    "n_hidden = 900\n",
    "n_mixt_attention = 10\n",
    "n_mixt_output = 20\n",
    "batch_size = 50\n",
    "\n",
    "train_it, = torchtext.data.BucketIterator.splits((train_ds,), batch_size=batch_size, repeat=False)\n",
    "val_it,   = torchtext.data.BucketIterator.splits((val_ds,),   batch_size=batch_size, repeat=False)\n",
    "\n",
    "m = HandwritingModel(n_hidden, n_chars, n_mixt_attention, n_mixt_output)\n",
    "m.cuda()\n",
    "# These are based on Graves Section 4.2.\n",
    "opt = torch.optim.RMSprop(m.parameters(), lr=1e-4, eps=1e-4, alpha=0.95, momentum=0.9, centered=True) \n",
    "losses = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0255,  0.0277, -0.0078,  ..., -0.0137, -0.0083, -0.0129],\n",
       "        [ 0.0300,  0.0177,  0.0301,  ..., -0.0260,  0.0260, -0.0072],\n",
       "        [-0.0187, -0.0253,  0.0195,  ..., -0.0173, -0.0155, -0.0277],\n",
       "        ...,\n",
       "        [ 0.0310, -0.0084,  0.0190,  ..., -0.0184,  0.0174, -0.0148],\n",
       "        [-0.0328,  0.0162,  0.0219,  ...,  0.0089,  0.0126,  0.0026],\n",
       "        [-0.0016, -0.0127, -0.0148,  ..., -0.0069, -0.0005,  0.0277]],\n",
       "       device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(m.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the training. If you want to skip the training, skip the next cell and enable the loading below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "496A24D27A3B4D938DD9629F08DAF456",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "smoothloss -299.7712777709961\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time per minibatch 3.461530828475952\n",
      "0 / 180 (of 208) : -281.6153564453125\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(50):\n",
    "    lasttime = time.time()\n",
    "    lastbatch = -1\n",
    "    epochstart = lasttime\n",
    "    for batch,i in enumerate(train_it):\n",
    "        #i_seq_pt, i_seq_tg, i_seq_mask, i_seq_str, i_seq_str_mask = [torch.autograd.Variable(torch.from_numpy(i).cuda()) for i in inputs]\n",
    "        #i_seq_str = i_seq_str.long()\n",
    "        i_seq_pt = torch.stack([i.xs, i.ys, i.pen.float()], dim=2).cuda()\n",
    "        i_seq_tg = i_seq_pt[1:].cuda()\n",
    "        i_seq_pt = i_seq_pt[:-1].cuda()\n",
    "        i_seq_mask = (i.pen[:-1]>=0).float().cuda()\n",
    "        i_seq_str = i.txtn.cuda()\n",
    "        i_seq_str_mask = i.txtmask.cuda()\n",
    "        \n",
    "        opt.zero_grad()\n",
    "        res = m(i_seq_pt, i_seq_mask, i_seq_tg, i_seq_str, i_seq_str_mask)\n",
    "        res.backward()\n",
    "        losses.append(res.data)\n",
    "        if batch % 10 == 0:\n",
    "            losses = [float(l) for l in losses]\n",
    "            IPython.display.clear_output(wait=True)\n",
    "            pyplot.figure(figsize=(15,5))\n",
    "            pyplot.subplot(1,2,1)\n",
    "            pyplot.plot(losses)\n",
    "            if len(losses)>=50:\n",
    "                smoothed = (numpy.convolve(losses,numpy.ones(50)/50,'valid'))\n",
    "                pyplot.plot(numpy.arange(len(losses)-len(smoothed),len(losses)),smoothed)\n",
    "                print (\"smoothloss\", smoothed[-1])\n",
    "            pyplot.subplot(1,2,2)\n",
    "            with torch.no_grad():\n",
    "                i_seq_str = torch.autograd.Variable(torch.LongTensor([int(char_dict[c]) for c in \"Die Katzen von Kopenhagen. \"]).view(-1,1).cuda())\n",
    "                i_seq_str_mask = torch.autograd.Variable(torch.ones(i_seq_str.size()).cuda())\n",
    "                seq_pt, seq_mask = m.predict(i_seq_pt[0,:1], i_seq_str, i_seq_str_mask, bias=0.8)\n",
    "                lengths = seq_mask.sum(0).data.long()\n",
    "                idx = 0\n",
    "                show_stroke(seq_pt.data.cpu()[:lengths[idx],idx])\n",
    "                #''.join([inv_char_dict[c] for c in i_seq_str.data.cpu()[:,idx]])\n",
    "            pyplot.show()\n",
    "            print (\"time per minibatch\",(time.time()-lasttime)/(batch-lastbatch))\n",
    "            lastbatch = batch\n",
    "            lasttime = time.time()\n",
    "            print (epoch,'/', batch,'(of 208) :', res.item())\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm(m.parameters(),5)\n",
    "        opt.step()\n",
    "    print (\"epoch\", epoch, \"took\", time.time()-epochstart, \"seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes I miss the output above, so here is the loss graph again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "E210C2A610FE401A924EA97DC8998CB4"
   },
   "outputs": [],
   "source": [
    "IPython.display.clear_output(wait=True)\n",
    "pyplot.plot(numpy.fmin(losses,3000))\n",
    "if len(losses)>=50:\n",
    "    smoothed = (numpy.convolve(losses,numpy.ones(50)/50,'valid'))\n",
    "    pyplot.plot(numpy.arange(len(losses)-len(smoothed),len(losses)),numpy.fmin(smoothed,3000))\n",
    "    print (\"smoothloss\", smoothed[-1])\n",
    "pyplot.show()\n",
    "print (epoch,'/', batch,'(of 208) :', res.item())            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can evaluate the negative log likelihood on the validation set. We should reach the same ballpark as Graves, who reports -1096.9 for the non-adaptive weight noise, albeit for a three-layer network) in Table 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    totalweight = 0.0\n",
    "    totalweightedloss = 0.0\n",
    "    for i in tqdm.tqdm(val_it): #, total=len(val_it)):\n",
    "        i_seq_pt = torch.stack([i.xs, i.ys, i.pen.float()], dim=2)\n",
    "        i_seq_tg = i_seq_pt[1:]\n",
    "        i_seq_pt = i_seq_pt[:-1]\n",
    "        i_seq_mask = (i.pen[:-1]>=0).float()\n",
    "        i_seq_str = i.txtn\n",
    "        i_seq_str_mask = i.txtmask\n",
    "        loss = m(i_seq_pt, i_seq_mask, i_seq_tg, i_seq_str, i_seq_str_mask).item()\n",
    "        lossweight = i.batch_size/val_it.batch_size\n",
    "        totalweight += lossweight\n",
    "        totalweightedloss += loss*lossweight\n",
    "print(\"Negative log likelihood on validation set\", totalweightedloss/totalweight)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want, you can load and save the model with the code below. It is more customary to use torch.save, but sometimes I like to save the weights only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "def save_to_hdf5(fn, d):\n",
    "    f = h5py.File(fn, \"w\")\n",
    "    for k,v in d.items():\n",
    "        f.create_dataset(k, data=v)\n",
    "def load_from_hdf5(fn):\n",
    "    f = h5py.File(fn, \"r\")\n",
    "    print (list(f.keys()))\n",
    "    return {k:v[:] for k,v in f.items()}\n",
    "\n",
    "if 0:\n",
    "    save_to_hdf5(\"graves_handwriting_generation_\"+time.strftime(\"%Y-%m-%d-%H-%M\",time.localtime())+\"epoch_{}\".format(epoch)+\".hd5\", {n:p.data.cpu().numpy() for n,p in m.named_parameters()})\n",
    "if 0:\n",
    "    d =load_from_hdf5(\"graves_handwriting_generation_2018-03-13-02-45epoch_49.hd5\")\n",
    "    for n,p in m.named_parameters():\n",
    "        p.data.copy_(torch.from_numpy(d[n]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visual model evaluation\n",
    "\n",
    "Nw that we have a model, we may show some samples.\n",
    "First we use the bias parameter as Graves describes in Section 5.4 and shows in Figure 16."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for bias in [0,2,2,2,5,5,5,100,100,100]:\n",
    "    with torch.no_grad():\n",
    "        i = next(iter(train_it))\n",
    "        i_seq_pt = torch.stack([i.xs, i.ys, i.pen.float()], dim=2)\n",
    "        i_seq_pt = i_seq_pt[:-1]\n",
    "\n",
    "        i_seq_str = torch.autograd.Variable(torch.LongTensor([int(char_dict[c]) for c in \"Die Katzen von Kopenhagen. \"]).view(-1,1).cuda())\n",
    "        i_seq_str_mask = torch.autograd.Variable(torch.ones(i_seq_str.size()).cuda())\n",
    "        seq_pt, seq_mask = m.predict(i_seq_pt[0,:1], i_seq_str, i_seq_str_mask, bias=bias)\n",
    "        lengths = seq_mask.sum(0).data.long()\n",
    "        idx = 0\n",
    "        pyplot.figure(figsize=(10,2))\n",
    "        show_stroke(seq_pt.data.cpu()[:lengths[idx],idx])\n",
    "        #''.join([inv_char_dict[c] for c in i_seq_str.data.cpu()[:,idx]])\n",
    "        pyplot.title(\"bias={}\".format(bias))\n",
    "        pyplot.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that even with an extreme bias, the generated writing is not identical. This is in contrast to Graves' observation in Figure 16. I tentatively believe this is due to several modes sharing the top spot for the weights (e.g. two having mass almost exactly 0.5). Also the pen write vs. move probability is not biased."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "4F00536FD70B4DDA8447E83163E4E4AD"
   },
   "source": [
    "### Model internal state\n",
    "\n",
    "In Order to look at model internals, we can a pass a Python defaultdict to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = collections.defaultdict(list)\n",
    "with torch.no_grad():\n",
    "        i = next(iter(train_it))\n",
    "        i_seq_pt = torch.stack([i.xs, i.ys, i.pen.float()], dim=2)\n",
    "        i_seq_tg = i_seq_pt[1:]\n",
    "        i_seq_pt = i_seq_pt[:-1]\n",
    "        i_seq_mask = (i.pen[:-1]>=0).float()\n",
    "        i_seq_str = i.txtn\n",
    "        i_seq_str_mask = i.txtmask\n",
    "        \n",
    "        opt.zero_grad()\n",
    "        res = m(i_seq_pt, i_seq_mask, i_seq_tg, i_seq_str, i_seq_str_mask, hidden_dict=d)\n",
    "d.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx=1\n",
    "this_batch_size = i_seq_pt.size(1)\n",
    "pts = i_seq_pt[:i.ptslen[0,idx],idx].cpu()\n",
    "pts_len = i.ptslen[0,idx]\n",
    "mean_y = d['mean_y'][0].view(-1,this_batch_size, d['mean_y'][0].size(1))[:pts_len,idx]*train_ds.coord_std[1]+train_ds.coord_mean[1]\n",
    "mean_x = d['mean_x'][0].view(-1,this_batch_size, d['mean_x'][0].size(1))[:pts_len,idx]*train_ds.coord_std[0]+train_ds.coord_mean[0]\n",
    "pi   = d['pi'][0].view(-1,this_batch_size, d['pi'][0].size(1))[:pts_len,idx]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The weights of the probabilities look reasonably similar to Graves Figure 14 in that we movements within strokes and in between being sampled from different mixture components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.figure(figsize=(15,5))\n",
    "pyplot.imshow(pi.t(), aspect='auto')\n",
    "#pts = torch.stack([i.xs,i.ys,i.pen.float()],dim=-1)\n",
    "pyplot.figure(figsize=(15,5))\n",
    "show_stroke(pts)\n",
    "txt = train_ds.tensor_to_str(i.txt[:i.txtlen[0,idx],idx])\n",
    "txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we want to visualize the probability distributions for the points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_mixture_of_normals(x, y, sx, sy, rho, weights):\n",
    "    x = x.view(1,1,-1)\n",
    "    y = y.view(1,1,-1)\n",
    "    sx = sx.view(1,1,-1)\n",
    "    sy = sy.view(1,1,-1)\n",
    "    rho = rho.view(1,1,-1)\n",
    "    weights = weights.view(1,1,-1)\n",
    "    xmin, ymin = x.min(), y.min()\n",
    "    xmax, ymax = x.max(), y.max()\n",
    "    NX, NY = 1000, 70\n",
    "    xx = torch.arange(0., NX).view(1,-1,1)*(xmax-xmin)/NX+xmin\n",
    "    yy = torch.arange(0., NY).view(-1,1,1)*(ymax-ymin)/NY+ymin\n",
    "    x_s = (x-xx)/sx\n",
    "    y_s = (y-yy)/sy\n",
    "    tmp = 1-rho**2\n",
    "    log_dens = -(x_s**2+y_s**2-2*rho*x_s*y_s)/(2*tmp)-numpy.log(2*numpy.pi)-torch.log(sx)- torch.log(sy) - 0.5*torch.log(tmp)\n",
    "    dens = (weights*torch.exp(log_dens)).sum(-1)\n",
    "    pyplot.imshow(dens**0.25, aspect='auto') # note: the **0.25 is only for the color mapping\n",
    "\n",
    "\n",
    "idx=1\n",
    "this_batch_size = i_seq_pt.size(1)\n",
    "pts = i_seq_pt[:i.ptslen[0,idx],idx].cpu()\n",
    "pts_len = i.ptslen[0,idx]\n",
    "cut_pts_len = min(pts_len, 100)\n",
    "mean_x = d['mean_x'][0].view(-1,this_batch_size, d['mean_x'][0].size(1))[:cut_pts_len,idx]*train_ds.coord_std[0]+train_ds.coord_mean[0]\n",
    "mean_y = d['mean_y'][0].view(-1,this_batch_size, d['mean_y'][0].size(1))[:cut_pts_len,idx]*train_ds.coord_std[1]+train_ds.coord_mean[1]\n",
    "std_x  = d['std_x'][0].view(-1,this_batch_size,  d['std_x'][0].size(1))[:cut_pts_len,idx]*train_ds.coord_std[0]\n",
    "std_y  = d['std_y'][0].view(-1,this_batch_size,  d['std_y'][0].size(1))[:cut_pts_len,idx]*train_ds.coord_std[1]\n",
    "pi     = d['pi'][0].view(-1,this_batch_size,  d['pi'][0].size(1))[:cut_pts_len,idx].contiguous()\n",
    "rho    = d['rho'][0].view(-1,this_batch_size, d['rho'][0].size(1))[:cut_pts_len,idx].contiguous()\n",
    "_,maxidx = pi.max(1)\n",
    "offset_x = torch.cat([torch.zeros(1),mean_x[torch.arange(0,len(mean_x), out=torch.LongTensor()), maxidx].cumsum(0)[:-1]],0)\n",
    "offset_y = torch.cat([torch.zeros(1),mean_y[torch.arange(0,len(mean_y), out=torch.LongTensor()), maxidx].cumsum(0)[:-1]],0)\n",
    "\n",
    "if 0:\n",
    "    NP = 10\n",
    "    x = torch.randn(NP)\n",
    "    y = torch.randn(NP)\n",
    "    sx = torch.exp(-1.5+0.5*torch.randn(NP))\n",
    "    sy = torch.exp(-1.5+0.5*torch.randn(NP))\n",
    "    rho = torch.zeros(NP)\n",
    "    weights = torch.ones(NP)\n",
    "pyplot.figure(figsize=(15,5))\n",
    "show_mixture_of_normals(mean_x+offset_x.unsqueeze(1), mean_y+offset_y.unsqueeze(1), std_x, std_y, rho, pi)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In contrast to Figure 14 in Graves, we do not see that much of the increased uncertainty (but note with Graves that in Figure 14 the uncertainty is much smaller for the moves to a new stroke than in the non-conditioned output of Figure 10). This may mean our model is overfitting more than his. Graves uses regularisation with adaptive weighted noise which - to the best of my understanding - is very similar to the recently more popular Bayesian Variational Inference scheme.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also recreate figure 13. To illustrate which character is dominant in the attention mechanism, we color the strokes accordingly. (I first saw colored strokes at [David Ha aka Hardmaru's blog](http://blog.otoro.net/2015/12/12/handwriting-generation-demo-in-tensorflow/), but at first glance he seems to color strokes, but we colorcode the attentention on chars.) It seems that the model looks at the next character quite early."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_phi  = d['seq_phi'][0][:pts_len,:, idx]\n",
    "pyplot.figure(figsize=(15,5))\n",
    "pyplot.imshow(d['seq_phi'][0][:pts_len,:, idx].t(), aspect=\"auto\")\n",
    "ax = pyplot.gca()\n",
    "ax.set_yticks(range(i.txtlen[0,idx].item()))\n",
    "ax.set_yticklabels(list(txt))\n",
    "pyplot.figure(figsize=(15,2))\n",
    "colorlist = [pyplot.cm.jet(int(5*i/(seq_phi.size(1)-1)*(pyplot.cm.jet.N-1))%256) for i in range(seq_phi.size(1))]\n",
    "colors = [colorlist[c] for c in seq_phi.max(1)[1].tolist()]\n",
    "show_stroke(pts, colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I hope you enjoyed the exploration of Graves' classic model as much as I did writing it.\n",
    "\n",
    "Feedback and corrections are always welcome at <tv@lernapparat.de>, I read and appreciate every mail.\n",
    "\n",
    "*Thomas Viehmann*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
